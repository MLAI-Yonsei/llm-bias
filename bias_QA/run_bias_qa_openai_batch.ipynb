{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import getpass\n",
    "import tiktoken\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "enc = tiktoken.encoding_for_model('gpt-4')\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_input_batch_file(prompts=None, batch_name=None, model='4o'):\n",
    "    if model == '4omini': gpt = 'gpt-4o-mini-2024-07-18'\n",
    "    elif model == '4o': gpt = 'gpt-4o-2024-11-20'\n",
    "    elif model == '41mini': gpt = 'gpt-4.1-mini-2025-04-14'\n",
    "    elif model == '41': gpt = 'gpt-4.1-2025-04-14'\n",
    "\n",
    "    print('Call ', gpt)\n",
    "    k = 0\n",
    "    batch_list = []\n",
    "    for i, prompt in tqdm(enumerate(prompts)):\n",
    "        tmp_input = {\"custom_id\": f\"{batch_name}_{i}\",\n",
    "                     \"method\": \"POST\",\n",
    "                     \"url\": \"/v1/chat/completions\",\n",
    "                     \"body\": {\"model\": gpt,\n",
    "                              \"messages\": prompt,\n",
    "                              \"max_tokens\": 1024,\n",
    "                              \"temperature\": 1.0,\n",
    "                              \"top_p\": 1,\n",
    "                              \"frequency_penalty\":0, \"presence_penalty\":0,\n",
    "                             }}\n",
    "    \n",
    "        batch_list.append(tmp_input)\n",
    "    \n",
    "        if len(batch_list) >= 40000:\n",
    "            with open(f\"./data/batch_files/{batch_name}_{k}.jsonl\", 'w') as jsonl_file:\n",
    "                for item in batch_list:\n",
    "                    jsonl_file.write(json.dumps(item) + '\\n')\n",
    "            k += 1\n",
    "            batch_list = []\n",
    "    \n",
    "    with open(f\"./data/batch_files/{batch_name}_{k}.jsonl\", 'w') as jsonl_file:\n",
    "        for item in batch_list:\n",
    "            jsonl_file.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_api(client, batch_files, batch_info_path):\n",
    "    # Load existing batch info if it exists\n",
    "    batch_dict = {}\n",
    "    batch_info_file = os.path.join(batch_info_path, \"batch_info.json\")\n",
    "    if os.path.exists(batch_info_file):\n",
    "        with open(batch_info_file, 'r') as f:\n",
    "            batch_dict = json.load(f)\n",
    "    \n",
    "    for i, batch_name in tqdm(enumerate(batch_files), total=len(batch_files)):\n",
    "        tmp = batch_name.split(\"/\")[-1].split(\".\")[0]\n",
    "        batch_input_file = client.files.create(\n",
    "                        file=open(batch_name, \"rb\"),\n",
    "                        purpose=\"batch\")\n",
    "\n",
    "        batch_input_file_id = batch_input_file.id    \n",
    "        batch_obj = client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "                \"cid\": tmp\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        # Update or add new batch info\n",
    "        batch_dict[tmp] = {\n",
    "            'input_file_id': batch_input_file_id,\n",
    "            'batch_api_obj_id': batch_obj.id\n",
    "        }\n",
    "\n",
    "    with open(batch_info_file, 'w') as f:\n",
    "        json.dump(batch_dict, f)\n",
    "\n",
    "    return batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_api_update(batch_info_path, client):\n",
    "    if os.path.exists(os.path.join(batch_info_path, \"batch_info.json\")):\n",
    "        with open(os.path.join(batch_info_path, \"batch_info.json\"), \"r\", encoding=\"utf-8\") as file:\n",
    "            batch_dict = json.load(file)\n",
    "            \n",
    "    c = 0\n",
    "    for k in batch_dict.keys():\n",
    "        try:\n",
    "            status = client.batches.retrieve(batch_dict[k]['batch_api_obj_id']).status\n",
    "        \n",
    "            if status == 'completed':\n",
    "                print(k, \" is completed\")\n",
    "                output_file_id = client.batches.retrieve(batch_dict[k]['batch_api_obj_id']).output_file_id\n",
    "                # Only update output_file_id if it's not already set\n",
    "                if 'output_file_id' not in batch_dict[k] or batch_dict[k]['output_file_id'] is None:\n",
    "                    batch_dict[k]['output_file_id'] = output_file_id\n",
    "            else:\n",
    "                print(k, f\" is {status}\")\n",
    "                c += 1\n",
    "                # Only set output_file_id to None if it's not already set\n",
    "                if 'output_file_id' not in batch_dict[k]:\n",
    "                    batch_dict[k]['output_file_id'] = None\n",
    "        except: pass\n",
    "    \n",
    "    with open(os.path.join(batch_info_path, \"batch_info.json\"), 'w') as f:\n",
    "        json.dump(batch_dict ,f)\n",
    "\n",
    "    if c == 0: print(\"RUN COMPLTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path = f'./data/finfairnessQA_prompt.jsonl'\n",
    "prompts = []\n",
    "with open(prompt_path, 'r') as f:\n",
    "    for line in f:\n",
    "        prompts.append(json.loads(line.strip()))\n",
    "prompts = prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_path = f'./data/finfairnessQA_prompt_w_g.jsonl'\n",
    "prompts_w_g = []\n",
    "with open(prompt_path, 'r') as f:\n",
    "    for line in f:\n",
    "        prompts_w_g.append(json.loads(line.strip()))\n",
    "prompts_w_g = prompts_w_g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call  gpt-4o-2024-11-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 201649.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call  gpt-4o-2024-11-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 598180.94it/s]\n"
     ]
    }
   ],
   "source": [
    "save_input_batch_file(prompts=prompts, batch_name=f'finfairnessqa_task', model='4o')\n",
    "save_input_batch_file(prompts=prompts_w_g, batch_name=f'finfairnessqa_task_w_g', model='4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/batch_files/finfairnessqa_task_w_g_0.jsonl', './data/batch_files/finfairnessqa_task_0.jsonl']\n"
     ]
    }
   ],
   "source": [
    "batch_files = glob(f\"./data/batch_files/*finfairnessqa_task*.jsonl\")\n",
    "print(batch_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'finfairnessqa_task_w_g_0': {'input_file_id': 'file-EGck3o3SyVo6W2s4Hry1Nt',\n",
       "  'batch_api_obj_id': 'batch_6845644d8dc4819084ab7411dbae8838'},\n",
       " 'finfairnessqa_task_0': {'input_file_id': 'file-2guDAbTsRYyuQwn7oRGddN',\n",
       "  'batch_api_obj_id': 'batch_6845644e8534819087ea3a4a8d339087'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_info_path = \"./data/batch_files\"\n",
    "run_batch_api(client, batch_files, batch_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finfairnessqa_task_w_g_0  is in_progress\n",
      "finfairnessqa_task_0  is in_progress\n"
     ]
    }
   ],
   "source": [
    "batch_api_update(batch_info_path, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_output_files(output_file_id):\n",
    "    responses = []\n",
    "    output_response = client.files.content(output_file_id)\n",
    "    for i, r in tqdm(enumerate(output_response.iter_lines())):\n",
    "        res = json.loads(r)\n",
    "        responses.append(res['response']['body']['choices'][0]['message']['content'])\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finfairnessqa_task_w_g_0  is completed\n",
      "finfairnessqa_task_0  is completed\n",
      "RUN COMPLTED\n"
     ]
    }
   ],
   "source": [
    "batch_info_path = \"./data/batch_files\"\n",
    "batch_api_update(batch_info_path, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finfairnessqa_task_w_g_0': {'input_file_id': 'file-EGck3o3SyVo6W2s4Hry1Nt',\n",
       "  'batch_api_obj_id': 'batch_6845644d8dc4819084ab7411dbae8838',\n",
       "  'output_file_id': 'file-EeU1mPuR9LPzBedjQqhqvp'},\n",
       " 'finfairnessqa_task_0': {'input_file_id': 'file-2guDAbTsRYyuQwn7oRGddN',\n",
       "  'batch_api_obj_id': 'batch_6845644e8534819087ea3a4a8d339087',\n",
       "  'output_file_id': 'file-RwjrVvwn8KwoSzj86rpGin'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(batch_info_path, \"batch_info.json\"), 'r') as f:\n",
    "    batch_list = json.load(f)\n",
    "{k: v for k, v in batch_list.items() if v['output_file_id'] is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:00, 96251.58it/s]\n"
     ]
    }
   ],
   "source": [
    "prompt_title = 'finfairnessqa_task_w_g'\n",
    "\n",
    "preds = load_output_files(batch_list[f'{prompt_title}_0']['output_file_id'])\n",
    "preds = ['답변거부' if '답변' in p else p for p in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA task result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/bias_qa_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response'] = preds\n",
    "df['Acc'] = (df['정답'] == df['response']).astype(int)\n",
    "accuracy = (df['정답'] == df['response']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7059\n",
      "Financial QA Accuracy: 0.5833\n",
      "Bias QA Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# f- : 금융분야 지식 QA\n",
    "f_accuracy = (df[df.Index.str.startswith('f-')]['정답'] == df[df.Index.str.startswith('f-')]['response']).mean()\n",
    "\n",
    "print(f\"Financial QA Accuracy: {f_accuracy:.4f}\")\n",
    "\n",
    "# b- : 편향성 QA\n",
    "b_accuracy = (df[df.Index.str.startswith('b-')]['정답'] == df[df.Index.str.startswith('b-')]['response']).mean()\n",
    "print(f\"Bias QA Accuracy: {b_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(54.11764705882353)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['response'] == '답변거부').mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./results/bias_qa_results_gpt4o_w_input_guardrails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
